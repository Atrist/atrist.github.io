{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[29],{572:function(t,s,a){\"use strict\";a.r(s);var n=a(5),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":t.$parent.slotKey}},[a(\"h2\",{attrs:{id:\"参考资料\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#参考资料\"}},[t._v(\"#\")]),t._v(\" 参考资料\")]),t._v(\" \"),a(\"ul\",[a(\"li\",[a(\"a\",{attrs:{href:\"https://codelabs.developers.google.com/codelabs/tfjs-training-classfication/index.html#0\",target:\"_blank\",rel:\"noopener noreferrer\"}},[t._v(\"TensorFlow 官方 带有 CNN 的手写数字识别的教程\"),a(\"OutboundLink\")],1)])]),t._v(\" \"),a(\"h2\",{attrs:{id:\"_1-介绍\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_1-介绍\"}},[t._v(\"#\")]),t._v(\" 1. 介绍\")]),t._v(\" \"),a(\"p\",[t._v(\"在本教程中，我们将构建一个 TensorFlow.js 模型来使用卷积神经网络识别手写数字。首先，我们将通过分类器“观察”数千个手写数字图像及其标签来训练分类器。然后，我们将使用模型从未见过的测试数据来评估分类器的准确性。\")]),t._v(\" \"),a(\"p\",[t._v(\"该任务被视为分类任务，因为我们正在训练模型以将类别（出现在图像中的数字）分配给输入图像。我们将通过显示许多输入示例以及正确的输出来训练模型。这被称为\"),a(\"a\",{attrs:{href:\"https://developers.google.com/machine-learning/problem-framing/cases\",target:\"_blank\",rel:\"noopener noreferrer\"}},[t._v(\"监督学习\"),a(\"OutboundLink\")],1),t._v(\"。\")]),t._v(\" \"),a(\"h3\",{attrs:{id:\"你将会做什么\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#你将会做什么\"}},[t._v(\"#\")]),t._v(\" 你将会做什么\")]),t._v(\" \"),a(\"p\",[t._v(\"您将创建一个使用 TensorFlow.js 在浏览器中训练模型的网页。给定特定尺寸的黑白图像，它将对出现在图像中的数字进行分类。涉及的步骤是：\")]),t._v(\" \"),a(\"ol\",[a(\"li\",[t._v(\"加载数据。\")]),t._v(\" \"),a(\"li\",[t._v(\"定义模型的架构。\")]),t._v(\" \"),a(\"li\",[t._v(\"训练模型并在训练时监视其性能。\")]),t._v(\" \"),a(\"li\",[t._v(\"通过做出一些预测来评估训练后的模型。\")])]),t._v(\" \"),a(\"h3\",{attrs:{id:\"你将学到什么\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#你将学到什么\"}},[t._v(\"#\")]),t._v(\" 你将学到什么\")]),t._v(\" \"),a(\"ul\",[a(\"li\",[t._v(\"TensorFlow.js 语法，用于使用 TensorFlow.js Layers API 创建卷积模型。\")]),t._v(\" \"),a(\"li\",[t._v(\"在 TensorFlow.js 中制定分类任务\")]),t._v(\" \"),a(\"li\",[t._v(\"如何使用 tfjs-vis 库监视浏览器内训练。\")])]),t._v(\" \"),a(\"h2\",{attrs:{id:\"_2-开始\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_2-开始\"}},[t._v(\"#\")]),t._v(\" 2. 开始\")]),t._v(\" \"),a(\"h3\",{attrs:{id:\"创建一个html页面并包含javascript\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#创建一个html页面并包含javascript\"}},[t._v(\"#\")]),t._v(\" 创建一个HTML页面并包含JavaScript\")]),t._v(\" \"),a(\"p\",[t._v(\"将以下代码复制到一个名为\"),a(\"code\",[t._v(\"index.html\")]),t._v(\"的\"),a(\"code\",[t._v(\"html\")]),t._v(\"文件中\")]),t._v(\" \"),a(\"div\",{staticClass:\"language-html line-numbers-mode\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-html\"}},[a(\"code\",[a(\"span\",{pre:!0,attrs:{class:\"token doctype\"}},[t._v(\"<!DOCTYPE html>\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),t._v(\"html\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),t._v(\"head\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),t._v(\"meta\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token attr-name\"}},[t._v(\"charset\")]),a(\"span\",{pre:!0,attrs:{class:\"token attr-value\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"=\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v('\"')]),t._v(\"utf-8\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v('\"')])]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),t._v(\"meta\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token attr-name\"}},[t._v(\"http-equiv\")]),a(\"span\",{pre:!0,attrs:{class:\"token attr-value\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"=\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v('\"')]),t._v(\"X-UA-Compatible\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v('\"')])]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token attr-name\"}},[t._v(\"content\")]),a(\"span\",{pre:!0,attrs:{class:\"token attr-value\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"=\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v('\"')]),t._v(\"IE=edge\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v('\"')])]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),t._v(\"meta\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token attr-name\"}},[t._v(\"name\")]),a(\"span\",{pre:!0,attrs:{class:\"token attr-value\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"=\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v('\"')]),t._v(\"viewport\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v('\"')])]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token attr-name\"}},[t._v(\"content\")]),a(\"span\",{pre:!0,attrs:{class:\"token attr-value\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"=\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v('\"')]),t._v(\"width=device-width, initial-scale=1.0\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v('\"')])]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),t._v(\"title\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\"TensorFlow.js Tutorial\"),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"</\")]),t._v(\"title\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\"\\n\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"\\x3c!-- Import TensorFlow.js --\\x3e\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),t._v(\"script\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token attr-name\"}},[t._v(\"src\")]),a(\"span\",{pre:!0,attrs:{class:\"token attr-value\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"=\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v('\"')]),t._v(\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.0/dist/tf.min.js\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v('\"')])]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),a(\"span\",{pre:!0,attrs:{class:\"token script\"}}),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"</\")]),t._v(\"script\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"\\x3c!-- Import tfjs-vis --\\x3e\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),t._v(\"script\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token attr-name\"}},[t._v(\"src\")]),a(\"span\",{pre:!0,attrs:{class:\"token attr-value\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"=\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v('\"')]),t._v(\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-vis@1.0.2/dist/tfjs-vis.umd.min.js\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v('\"')])]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),a(\"span\",{pre:!0,attrs:{class:\"token script\"}}),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"</\")]),t._v(\"script\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\"\\n\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"\\x3c!-- Import the data file --\\x3e\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),t._v(\"script\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token attr-name\"}},[t._v(\"src\")]),a(\"span\",{pre:!0,attrs:{class:\"token attr-value\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"=\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v('\"')]),t._v(\"data.js\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v('\"')])]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token attr-name\"}},[t._v(\"type\")]),a(\"span\",{pre:!0,attrs:{class:\"token attr-value\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"=\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v('\"')]),t._v(\"module\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v('\"')])]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),a(\"span\",{pre:!0,attrs:{class:\"token script\"}}),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"</\")]),t._v(\"script\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\"\\n\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"\\x3c!-- Import the main script file --\\x3e\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),t._v(\"script\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token attr-name\"}},[t._v(\"src\")]),a(\"span\",{pre:!0,attrs:{class:\"token attr-value\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"=\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v('\"')]),t._v(\"script.js\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v('\"')])]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token attr-name\"}},[t._v(\"type\")]),a(\"span\",{pre:!0,attrs:{class:\"token attr-value\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"=\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v('\"')]),t._v(\"module\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v('\"')])]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),a(\"span\",{pre:!0,attrs:{class:\"token script\"}}),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"</\")]),t._v(\"script\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\"\\n\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"</\")]),t._v(\"head\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\"\\n\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),t._v(\"body\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"</\")]),t._v(\"body\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token tag\"}},[a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"</\")]),t._v(\"html\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\"\\n\")])]),t._v(\" \"),a(\"div\",{staticClass:\"line-numbers-wrapper\"},[a(\"span\",{staticClass:\"line-number\"},[t._v(\"1\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"2\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"3\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"4\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"5\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"6\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"7\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"8\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"9\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"10\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"11\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"12\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"13\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"14\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"15\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"16\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"17\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"18\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"19\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"20\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"21\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"22\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"23\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"24\")]),a(\"br\")])]),a(\"h3\",{attrs:{id:\"为数据和代码创建javascript文件\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#为数据和代码创建javascript文件\"}},[t._v(\"#\")]),t._v(\" 为数据和代码创建JavaScript文件\")]),t._v(\" \"),a(\"ol\",[a(\"li\",[a(\"p\",[t._v(\"在与上述HTML文件相同的文件夹中，创建一个名为\"),a(\"code\",[t._v(\"data.js\")]),t._v(\"的文件，并将内容从\"),a(\"a\",{attrs:{href:\"https://storage.googleapis.com/tfjs-tutorials/mnist_data.js\",target:\"_blank\",rel:\"noopener noreferrer\"}},[t._v(\"该链接\"),a(\"OutboundLink\")],1),t._v(\"复制到该文件中。\")])]),t._v(\" \"),a(\"li\",[a(\"p\",[t._v(\"在与第一步相同的文件夹中，创建一个名为\"),a(\"code\",[t._v(\"script.js\")]),t._v(\"的文件，并将以下代码放入其中。\")]),t._v(\" \"),a(\"div\",{staticClass:\"language-js line-numbers-mode\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-js\"}},[a(\"code\",[t._v(\"console\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"log\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'Hello TensorFlow'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\")])]),t._v(\" \"),a(\"div\",{staticClass:\"line-numbers-wrapper\"},[a(\"span\",{staticClass:\"line-number\"},[t._v(\"1\")]),a(\"br\")])])])]),t._v(\" \"),a(\"h4\",{attrs:{id:\"note\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#note\"}},[t._v(\"#\")]),t._v(\" NOTE\")]),t._v(\" \"),a(\"p\",[t._v(\"根据浏览器的权限，您可能需要使用本地Web服务器来查看文件，以便避开CORS限制。\")]),t._v(\" \"),a(\"p\",[a(\"a\",{attrs:{href:\"https://www.npmjs.com/package/http-server\",target:\"_blank\",rel:\"noopener noreferrer\"}},[t._v(\"Node http server\"),a(\"OutboundLink\")],1),t._v(\"是个不错的选择。\")]),t._v(\" \"),a(\"h3\",{attrs:{id:\"测试\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#测试\"}},[t._v(\"#\")]),t._v(\" 测试\")]),t._v(\" \"),a(\"p\",[t._v(\"如果一切正常，则应该创建两个全局变量。 tf是对TensorFlow.js库的引用，tfvis是对tfjs-vis库的引用。\")]),t._v(\" \"),a(\"p\",[t._v(\"您应该看到一条消息“ Hello TensorFlow”，如果是这样，则准备继续进行下一步。\")]),t._v(\" \"),a(\"h2\",{attrs:{id:\"_3-加载数据\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_3-加载数据\"}},[t._v(\"#\")]),t._v(\" 3. 加载数据\")]),t._v(\" \"),a(\"p\",[t._v(\"在本教程中，您将训练模型以学习识别图像中的数字，如下图所示。这些图像是来自称为\"),a(\"a\",{attrs:{href:\"http://yann.lecun.com/exdb/mnist/\",target:\"_blank\",rel:\"noopener noreferrer\"}},[t._v(\"MNIST\"),a(\"OutboundLink\")],1),t._v(\"的数据集的28x28px灰度图像。\")]),t._v(\" \"),a(\"p\",[a(\"img\",{attrs:{src:\"https://codelabs.developers.google.com/codelabs/tfjs-training-classfication/img/c01d85004462fd48.png\",alt:\"\"}}),a(\"img\",{attrs:{src:\"https://codelabs.developers.google.com/codelabs/tfjs-training-classfication/img/58d4cf23ee7202be.png\",alt:\"\"}}),a(\"img\",{attrs:{src:\"https://codelabs.developers.google.com/codelabs/tfjs-training-classfication/img/8998bab63049c12a.png\",alt:\"\"}})]),t._v(\" \"),a(\"p\",[t._v(\"我们提供了用于从为您创建的特殊\"),a(\"a\",{attrs:{href:\"https://storage.googleapis.com/learnjs-data/model-builder/mnist_images.png\",target:\"_blank\",rel:\"noopener noreferrer\"}},[t._v(\"Sprite文件\"),a(\"OutboundLink\")],1),t._v(\"（〜10MB）中加载这些图像的代码，以便我们可以专注于训练部分。\")]),t._v(\" \"),a(\"p\",[t._v(\"随时研究\"),a(\"a\",{attrs:{href:\"https://raw.githubusercontent.com/tensorflow/tfjs-examples/master/mnist-core/data.js\",target:\"_blank\",rel:\"noopener noreferrer\"}},[t._v(\"data.js\"),a(\"OutboundLink\")],1),t._v(\"文件以了解如何加载数据。或者，一旦完成本教程，就可以创建自己的加载数据的方法。\")]),t._v(\" \"),a(\"p\",[t._v(\"提供的代码包含一个具有两个公共方法的\"),a(\"code\",[t._v(\"MnistData\")]),t._v(\"类：\")]),t._v(\" \"),a(\"ul\",[a(\"li\",[a(\"code\",[t._v(\"nextTrainBatch（batchSize）\")]),t._v(\"：从训练集中返回图像及其标签的随机批次。\")]),t._v(\" \"),a(\"li\",[a(\"code\",[t._v(\"nextTestBatch（batchSize）\")]),t._v(\"：从测试集中返回一批图像及其标签\")])]),t._v(\" \"),a(\"p\",[t._v(\"MnistData类还执行\"),a(\"strong\",[t._v(\"重排\")]),t._v(\"和\"),a(\"strong\",[t._v(\"规范化\")]),t._v(\"数据的重要步骤。\")]),t._v(\" \"),a(\"p\",[t._v(\"总共有65,000张图像，我们将使用多达55,000张图像来训练模型，完成后可以保存10,000张图像以测试模型的性能。我们将在浏览器中完成所有这些工作！\")]),t._v(\" \"),a(\"blockquote\",[a(\"p\",[t._v(\"如果您在\"),a(\"code\",[t._v(\"Node.js\")]),t._v(\"中执行类似操作，则可能会直接从文件系统加载图像，并使用本机图像处理解决方案来获取像素数据。\")])]),t._v(\" \"),a(\"p\",[t._v(\"让我们加载数据并测试其是否正确加载。\")]),t._v(\" \"),a(\"p\",[a(\"strong\",[t._v(\"将以下代码添加到您的script.js文件中。\")])]),t._v(\" \"),a(\"div\",{staticClass:\"language-js line-numbers-mode\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-js\"}},[a(\"code\",[a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"import\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"MnistData\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"from\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'./data.js'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"async\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"function\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"showExamples\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token parameter\"}},[t._v(\"data\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// Create a container in the visor\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" surface \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\"\\n    tfvis\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"visor\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"surface\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\" name\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'Input Data Examples'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" tab\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'Input Data'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"  \\n\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// Get the examples\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" examples \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" data\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"nextTestBatch\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"20\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" numExamples \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" examples\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"xs\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"shape\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// Create a canvas element to render each example\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"for\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"let\")]),t._v(\" i \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\" i \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"<\")]),t._v(\" numExamples\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\" i\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"++\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" imageTensor \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" tf\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"tidy\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=>\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n      \"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// Reshape the image to 28x28 px\")]),t._v(\"\\n      \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"return\")]),t._v(\" examples\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"xs\\n        \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"slice\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"i\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" examples\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"xs\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"shape\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n        \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"reshape\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"28\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"28\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" canvas \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" document\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"createElement\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'canvas'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    canvas\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"width \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"28\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    canvas\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"height \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"28\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    canvas\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"style \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'margin: 4px;'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"await\")]),t._v(\" tf\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"browser\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"toPixels\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"imageTensor\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" canvas\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    surface\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"drawArea\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"appendChild\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"canvas\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n    imageTensor\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"dispose\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"async\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"function\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"run\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"  \\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" data \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"MnistData\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"await\")]),t._v(\" data\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"load\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"await\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"showExamples\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"data\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\\ndocument\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"addEventListener\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'DOMContentLoaded'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" run\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\")])]),t._v(\" \"),a(\"div\",{staticClass:\"line-numbers-wrapper\"},[a(\"span\",{staticClass:\"line-number\"},[t._v(\"1\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"2\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"3\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"4\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"5\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"6\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"7\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"8\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"9\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"10\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"11\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"12\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"13\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"14\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"15\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"16\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"17\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"18\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"19\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"20\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"21\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"22\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"23\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"24\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"25\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"26\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"27\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"28\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"29\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"30\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"31\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"32\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"33\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"34\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"35\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"36\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"37\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"38\")]),a(\"br\")])]),a(\"p\",[t._v(\"刷新页面，几秒钟后，您应该会在左侧看到一个包含大量图像的面板。\")]),t._v(\" \"),a(\"p\",[a(\"img\",{attrs:{src:\"https://codelabs.developers.google.com/codelabs/tfjs-training-classfication/img/6dff857738b54eed.png\",alt:\"\"}})]),t._v(\" \"),a(\"h2\",{attrs:{id:\"_4-概念化我们的任务\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_4-概念化我们的任务\"}},[t._v(\"#\")]),t._v(\" 4. 概念化我们的任务\")]),t._v(\" \"),a(\"p\",[t._v(\"我们的输入数据如下所示。\")]),t._v(\" \"),a(\"p\",[a(\"img\",{attrs:{src:\"https://codelabs.developers.google.com/codelabs/tfjs-training-classfication/img/6dff857738b54eed.png\",alt:\"\"}})]),t._v(\" \"),a(\"p\",[t._v(\"我们的目标是训练一个将拍摄一张图像的模型，并学习预测该图像可能属于的10个类别中的每个类别的得分（数字0-9）。\")]),t._v(\" \"),a(\"p\",[t._v(\"每个图像宽28像素，高28像素，并具有1个颜色通道，因为它是灰度图像。因此，每个图像的形状为\"),a(\"code\",[t._v(\"[28，28，1]\")]),t._v(\"。\")]),t._v(\" \"),a(\"p\",[t._v(\"请记住，我们要进行一对一的映射以及每个输入示例的形状，因为这对于下一节很重要。\")]),t._v(\" \"),a(\"h2\",{attrs:{id:\"_5-定义模型架构\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_5-定义模型架构\"}},[t._v(\"#\")]),t._v(\" 5. 定义模型架构\")]),t._v(\" \"),a(\"p\",[t._v(\"在本节中，我们将编写代码来描述模型架构。模型体系结构是一种说法：“模型在执行时将运行哪些功能”，或者“模型将使用哪种算法来计算其答案”。在机器学习中，我们定义一种架构（或算法），并让训练过程学习该算法的参数。\")]),t._v(\" \"),a(\"p\",[a(\"strong\",[t._v(\"将以下函数添加到您的\"),a(\"code\",[t._v(\"script.js\")]),t._v(\"文件中以定义模型架构\")])]),t._v(\" \"),a(\"div\",{staticClass:\"language-js line-numbers-mode\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-js\"}},[a(\"code\",[a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"function\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getModel\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" model \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" tf\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"sequential\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"IMAGE_WIDTH\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"28\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"IMAGE_HEIGHT\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"28\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"IMAGE_CHANNELS\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"  \\n  \\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// In the first layer of our convolutional neural network we have \")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// to specify the input shape. Then we specify some parameters for \")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// the convolution operation that takes place in this layer.\")]),t._v(\"\\n  model\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"add\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"tf\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"layers\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"conv2d\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n    inputShape\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"IMAGE_WIDTH\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"IMAGE_HEIGHT\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"IMAGE_CHANNELS\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n    kernelSize\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"5\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n    filters\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"8\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n    strides\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n    activation\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'relu'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n    kernelInitializer\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'varianceScaling'\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// The MaxPooling layer acts as a sort of downsampling using max values\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// in a region instead of averaging.  \")]),t._v(\"\\n  model\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"add\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"tf\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"layers\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"maxPooling2d\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"poolSize\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"2\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"2\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" strides\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"2\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"2\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// Repeat another conv2d + maxPooling stack. \")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// Note that we have more filters in the convolution.\")]),t._v(\"\\n  model\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"add\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"tf\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"layers\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"conv2d\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n    kernelSize\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"5\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n    filters\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"16\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n    strides\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n    activation\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'relu'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n    kernelInitializer\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'varianceScaling'\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  model\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"add\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"tf\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"layers\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"maxPooling2d\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"poolSize\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"2\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"2\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" strides\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"2\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"2\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// Now we flatten the output from the 2D filters into a 1D vector to prepare\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// it for input into our last layer. This is common practice when feeding\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// higher dimensional data to a final classification output layer.\")]),t._v(\"\\n  model\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"add\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"tf\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"layers\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"flatten\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// Our last layer is a dense layer which has 10 output units, one for each\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// output class (i.e. 0, 1, 2, 3, 4, 5, 6, 7, 8, 9).\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"NUM_OUTPUT_CLASSES\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"10\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  model\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"add\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"tf\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"layers\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"dense\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n    units\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"NUM_OUTPUT_CLASSES\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n    kernelInitializer\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'varianceScaling'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n    activation\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'softmax'\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n  \\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// Choose an optimizer, loss function and accuracy metric,\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// then compile and return the model\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" optimizer \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" tf\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"train\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"adam\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  model\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"compile\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n    optimizer\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" optimizer\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n    loss\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'categoricalCrossentropy'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n    metrics\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'accuracy'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"return\")]),t._v(\" model\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\")])]),t._v(\" \"),a(\"div\",{staticClass:\"line-numbers-wrapper\"},[a(\"span\",{staticClass:\"line-number\"},[t._v(\"1\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"2\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"3\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"4\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"5\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"6\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"7\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"8\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"9\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"10\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"11\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"12\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"13\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"14\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"15\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"16\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"17\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"18\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"19\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"20\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"21\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"22\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"23\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"24\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"25\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"26\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"27\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"28\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"29\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"30\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"31\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"32\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"33\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"34\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"35\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"36\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"37\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"38\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"39\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"40\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"41\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"42\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"43\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"44\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"45\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"46\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"47\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"48\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"49\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"50\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"51\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"52\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"53\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"54\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"55\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"56\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"57\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"58\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"59\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"60\")]),a(\"br\")])]),a(\"p\",[t._v(\"让我们更详细地看一下。\")]),t._v(\" \"),a(\"h3\",{attrs:{id:\"卷积\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#卷积\"}},[t._v(\"#\")]),t._v(\" 卷积\")]),t._v(\" \"),a(\"div\",{staticClass:\"language-js line-numbers-mode\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-js\"}},[a(\"code\",[t._v(\"model\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"add\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"tf\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"layers\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"conv2d\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n  inputShape\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"IMAGE_WIDTH\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"IMAGE_HEIGHT\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"IMAGE_CHANNELS\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n  kernelSize\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"5\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n  filters\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"8\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n  strides\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n  activation\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'relu'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n  kernelInitializer\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'varianceScaling'\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\")])]),t._v(\" \"),a(\"div\",{staticClass:\"line-numbers-wrapper\"},[a(\"span\",{staticClass:\"line-number\"},[t._v(\"1\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"2\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"3\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"4\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"5\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"6\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"7\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"8\")]),a(\"br\")])]),a(\"p\",[t._v(\"在这里，我们使用顺序模型。我们使用的是conv2d层而不是密集层。我们无法深入了解卷积如何工作的所有细节，但是这里有一些资源可以解释底层操作：\")]),t._v(\" \"),a(\"ul\",[a(\"li\",[a(\"a\",{attrs:{href:\"http://setosa.io/ev/image-kernels/\",target:\"_blank\",rel:\"noopener noreferrer\"}},[t._v(\"Image Kernels Explained Visually\"),a(\"OutboundLink\")],1)]),t._v(\" \"),a(\"li\",[a(\"a\",{attrs:{href:\"http://cs231n.github.io/convolutional-networks/\",target:\"_blank\",rel:\"noopener noreferrer\"}},[t._v(\"Convolutional Neural Networks for Visual Recognition\"),a(\"OutboundLink\")],1)])]),t._v(\" \"),a(\"p\",[t._v(\"让我们分解一下\"),a(\"code\",[t._v(\"conv2d\")]),t._v(\"的配置对象中的每个参数：\")]),t._v(\" \"),a(\"ul\",[a(\"li\",[a(\"code\",[t._v(\"inputShape\")]),t._v(\":流入模型第一层的数据的形状。在这种情况下，我们的MNIST示例为28x28像素的黑白图像。图像数据的规范格式为\"),a(\"code\",[t._v(\"[行，列，深度]\")]),t._v(\"，因此在这里我们要配置形状为\"),a(\"code\",[t._v(\"[28、28、1]\")]),t._v(\"。每个维度中的像素数为28行和列，深度为1，因为我们的图像只有1个颜色通道。请注意，我们没有在输入形状中指定批次大小。图层被设计为与批量大小无关，因此在推理期间，您可以传入任何批量大小的张量。\")]),t._v(\" \"),a(\"li\",[a(\"code\",[t._v(\"kernelSize\")]),t._v(\": 滑动卷积滤波器窗口的大小将应用于输入数据。在这里，我们将\"),a(\"code\",[t._v(\"kernelSize\")]),t._v(\"设置为5，它指定一个正方形的5x5卷积窗口。\")]),t._v(\" \"),a(\"li\",[a(\"code\",[t._v(\"filters\")]),t._v(\":要应用于输入数据的大小为\"),a(\"code\",[t._v(\"kernelSize\")]),t._v(\"的过滤器窗口数。在这里，我们将对数据应用8个过滤器。\")]),t._v(\" \"),a(\"li\",[a(\"code\",[t._v(\"strides\")]),t._v(\": 滑动窗口的“步长”，即滤镜每次在图像上移动时将移动多少像素。在此，我们将步幅指定为1，这表示滤镜将以1像素为步长在图像上滑动。\")]),t._v(\" \"),a(\"li\",[a(\"code\",[t._v(\"activation\")]),t._v(\":卷积完成后应用于数据的\"),a(\"a\",{attrs:{href:\"https://developers.google.com/machine-learning/glossary/#activation_function\",target:\"_blank\",rel:\"noopener noreferrer\"}},[t._v(\"激活函数\"),a(\"OutboundLink\")],1),t._v(\"。在这种情况下，我们将应用\"),a(\"a\",{attrs:{href:\"https://developers.google.com/machine-learning/glossary/#ReLU\",target:\"_blank\",rel:\"noopener noreferrer\"}},[t._v(\"整流线性单元（ReLU）\"),a(\"OutboundLink\")],1),t._v(\"，这是ML模型中非常常见的激活函数。\")]),t._v(\" \"),a(\"li\",[a(\"code\",[t._v(\"kernelInitializer\")]),t._v(\":用于随机初始化模型权重的方法，这对于训练动力学非常重要。在这里我们将不讨论初始化的详细信息，但是VarianceScaling（在此使用）通常是不错的\"),a(\"a\",{attrs:{href:\"https://js.tensorflow.org/api/latest/#Initializers\",target:\"_blank\",rel:\"noopener noreferrer\"}},[t._v(\"初始化选择\"),a(\"OutboundLink\")],1),t._v(\"。\")])]),t._v(\" \"),a(\"blockquote\",[a(\"p\",[t._v(\"您也可以只使用密集层来构建图像分类器，但是，卷积层已被证明对许多基于图像的任务有效。\")])]),t._v(\" \"),a(\"h3\",{attrs:{id:\"展平我们的数据表示\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#展平我们的数据表示\"}},[t._v(\"#\")]),t._v(\" 展平我们的数据表示\")]),t._v(\" \"),a(\"div\",{staticClass:\"language-js line-numbers-mode\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-js\"}},[a(\"code\",[t._v(\"model\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"add\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"tf\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"layers\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"flatten\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\")])]),t._v(\" \"),a(\"div\",{staticClass:\"line-numbers-wrapper\"},[a(\"span\",{staticClass:\"line-number\"},[t._v(\"1\")]),a(\"br\")])]),a(\"p\",[t._v(\"图像是高维数据，卷积操作往往会增加进入其中的数据的大小。在将它们传递到最终分类层之前，我们需要将数据展平为一个长数组。密集层（我们用作最后​​一层）仅需使用\"),a(\"code\",[t._v(\"tensor1d\")]),t._v(\"，因此此步骤在许多分类任务中很常见。\")]),t._v(\" \"),a(\"blockquote\",[a(\"p\",[t._v(\"注意：在平整层中没有权重。它只是将其输入展开为一个长数组。\")])]),t._v(\" \"),a(\"h3\",{attrs:{id:\"计算我们的最终概率分布\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#计算我们的最终概率分布\"}},[t._v(\"#\")]),t._v(\" 计算我们的最终概率分布\")]),t._v(\" \"),a(\"div\",{staticClass:\"language-js line-numbers-mode\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-js\"}},[a(\"code\",[a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"NUM_OUTPUT_CLASSES\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"10\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\nmodel\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"add\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"tf\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"layers\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"dense\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n  units\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"NUM_OUTPUT_CLASSES\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n  kernelInitializer\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'varianceScaling'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n  activation\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'softmax'\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\")])]),t._v(\" \"),a(\"div\",{staticClass:\"line-numbers-wrapper\"},[a(\"span\",{staticClass:\"line-number\"},[t._v(\"1\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"2\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"3\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"4\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"5\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"6\")]),a(\"br\")])]),a(\"p\",[t._v(\"我们将使用具有\"),a(\"code\",[t._v(\"softmax\")]),t._v(\"激活的密集层来计算10种可能类别上的概率分布。得分最高的班级将是预测的数字。\")]),t._v(\" \"),a(\"blockquote\",[a(\"p\",[t._v(\"记住，我们想要一比十的映射（一个输入图像到十个概率）。这就是为什么我们的输出层有10个单位的原因。 \"),a(\"br\"),t._v(\"\\n您可能希望在分类任务的最后一层使用\"),a(\"code\",[t._v(\"Softmax\")]),t._v(\"激活。\")])]),t._v(\" \"),a(\"h3\",{attrs:{id:\"选择一个优化器和损失函数\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#选择一个优化器和损失函数\"}},[t._v(\"#\")]),t._v(\" 选择一个优化器和损失函数\")]),t._v(\" \"),a(\"div\",{staticClass:\"language-js line-numbers-mode\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-js\"}},[a(\"code\",[a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" optimizer \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" tf\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"train\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"adam\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\nmodel\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"compile\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n  optimizer\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" optimizer\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n  loss\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'categoricalCrossentropy'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n  metrics\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'accuracy'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\")])]),t._v(\" \"),a(\"div\",{staticClass:\"line-numbers-wrapper\"},[a(\"span\",{staticClass:\"line-number\"},[t._v(\"1\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"2\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"3\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"4\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"5\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"6\")]),a(\"br\")])]),a(\"p\",[t._v(\"我们编译模型，指定要跟踪的\"),a(\"a\",{attrs:{href:\"https://developers.google.com/machine-learning/glossary/#optimizer\",target:\"_blank\",rel:\"noopener noreferrer\"}},[t._v(\"优化程序\"),a(\"OutboundLink\")],1),t._v(\"，\"),a(\"a\",{attrs:{href:\"https://developers.google.com/machine-learning/glossary/#optimizer\",target:\"_blank\",rel:\"noopener noreferrer\"}},[t._v(\"损失函数\"),a(\"OutboundLink\")],1),t._v(\"和指标。\")]),t._v(\" \"),a(\"p\",[t._v(\"与我们的第一个教程相反，这里我们使用\"),a(\"a\",{attrs:{href:\"https://developers.google.com/machine-learning/glossary/#cross-entropy\",target:\"_blank\",rel:\"noopener noreferrer\"}},[t._v(\"categoricalCrossentropy\"),a(\"OutboundLink\")],1),t._v(\"作为损失函数。顾名思义，当我们的模型输出是概率分布时，将使用此名称。\")]),t._v(\" \"),a(\"p\",[t._v(\"例如，如果我们的数字确实代表7，那么我们可能会得到以下结果\")]),t._v(\" \"),a(\"table\",[a(\"thead\",[a(\"tr\",[a(\"th\",[t._v(\"Index\")]),t._v(\" \"),a(\"th\",[t._v(\"0\")]),t._v(\" \"),a(\"th\",[t._v(\"1\")]),t._v(\" \"),a(\"th\",[t._v(\"2\")]),t._v(\" \"),a(\"th\",[t._v(\"3\")]),t._v(\" \"),a(\"th\",[t._v(\"4\")]),t._v(\" \"),a(\"th\",[t._v(\"5\")]),t._v(\" \"),a(\"th\",[t._v(\"6\")]),t._v(\" \"),a(\"th\",[t._v(\"7\")]),t._v(\" \"),a(\"th\",[t._v(\"8\")]),t._v(\" \"),a(\"th\",[t._v(\"9\")])])]),t._v(\" \"),a(\"tbody\",[a(\"tr\",[a(\"td\",[t._v(\"True Label\")]),t._v(\" \"),a(\"td\",[t._v(\"0\")]),t._v(\" \"),a(\"td\",[t._v(\"0\")]),t._v(\" \"),a(\"td\",[t._v(\"0\")]),t._v(\" \"),a(\"td\",[t._v(\"0\")]),t._v(\" \"),a(\"td\",[t._v(\"0\")]),t._v(\" \"),a(\"td\",[t._v(\"0\")]),t._v(\" \"),a(\"td\",[t._v(\"0\")]),t._v(\" \"),a(\"td\",[t._v(\"1\")]),t._v(\" \"),a(\"td\",[t._v(\"0\")]),t._v(\" \"),a(\"td\",[t._v(\"0\")])]),t._v(\" \"),a(\"tr\",[a(\"td\",[t._v(\"Prediction\")]),t._v(\" \"),a(\"td\",[t._v(\"0.1\")]),t._v(\" \"),a(\"td\",[t._v(\"0.01\")]),t._v(\" \"),a(\"td\",[t._v(\"0.01\")]),t._v(\" \"),a(\"td\",[t._v(\"0.01\")]),t._v(\" \"),a(\"td\",[t._v(\"0.20\")]),t._v(\" \"),a(\"td\",[t._v(\"0.01\")]),t._v(\" \"),a(\"td\",[t._v(\"0.01\")]),t._v(\" \"),a(\"td\",[t._v(\"0.60\")]),t._v(\" \"),a(\"td\",[t._v(\"0.03\")]),t._v(\" \"),a(\"td\",[t._v(\"0.02\")])])])]),t._v(\" \"),a(\"p\",[t._v(\"分类交叉熵将产生一个数字，指示预测矢量与我们的真实标签矢量有多相似。\")]),t._v(\" \"),a(\"p\",[t._v(\"此处用于标签的数据表示称为\"),a(\"strong\",[t._v(\"单热编码\")]),t._v(\"，在分类问题中很常见。对于每个示例，每个类别都有与之关联的概率。当我们确切知道应该是什么时，可以将该概率设置为1，将其他概率设置为0。有关单热编码的更多信息，请参见\"),a(\"a\",{attrs:{href:\"https://developers.google.com/machine-learning/crash-course/representation/feature-engineering\",target:\"_blank\",rel:\"noopener noreferrer\"}},[t._v(\"此页面\"),a(\"OutboundLink\")],1),t._v(\"。\")]),t._v(\" \"),a(\"p\",[t._v(\"我们将监视的另一个指标是\"),a(\"code\",[t._v(\"准确性\")]),t._v(\"，对于分类问题，\"),a(\"code\",[t._v(\"准确性\")]),t._v(\"是所有预测中正确预测的百分比。\")]),t._v(\" \"),a(\"h2\",{attrs:{id:\"训练模型\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#训练模型\"}},[t._v(\"#\")]),t._v(\" 训练模型\")]),t._v(\" \"),a(\"p\",[t._v(\"将以下函数复制到您的script.js文件中。\")]),t._v(\" \"),a(\"div\",{staticClass:\"language-js line-numbers-mode\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-js\"}},[a(\"code\",[a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"async\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"function\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"train\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token parameter\"}},[t._v(\"model\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" data\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" metrics \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'loss'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'val_loss'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'acc'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'val_acc'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" container \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n    name\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'Model Training'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" styles\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\" height\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'1000px'\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" fitCallbacks \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" tfvis\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"show\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"fitCallbacks\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"container\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" metrics\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"BATCH_SIZE\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"512\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"TRAIN_DATA_SIZE\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"5500\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"TEST_DATA_SIZE\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1000\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"trainXs\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" trainYs\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" tf\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"tidy\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=>\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" d \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" data\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"nextTrainBatch\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"TRAIN_DATA_SIZE\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"return\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"\\n      d\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"xs\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"reshape\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"TRAIN_DATA_SIZE\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"28\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"28\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n      d\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"labels\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"testXs\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" testYs\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" tf\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"tidy\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=>\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" d \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" data\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"nextTestBatch\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"TEST_DATA_SIZE\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"return\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"\\n      d\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"xs\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"reshape\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"TEST_DATA_SIZE\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"28\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"28\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n      d\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"labels\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"return\")]),t._v(\" model\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"fit\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"trainXs\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" trainYs\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n    batchSize\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"BATCH_SIZE\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n    validationData\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"testXs\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" testYs\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n    epochs\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"10\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n    shuffle\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[t._v(\"true\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n    callbacks\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" fitCallbacks\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\")])]),t._v(\" \"),a(\"div\",{staticClass:\"line-numbers-wrapper\"},[a(\"span\",{staticClass:\"line-number\"},[t._v(\"1\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"2\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"3\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"4\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"5\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"6\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"7\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"8\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"9\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"10\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"11\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"12\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"13\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"14\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"15\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"16\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"17\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"18\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"19\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"20\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"21\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"22\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"23\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"24\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"25\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"26\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"27\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"28\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"29\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"30\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"31\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"32\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"33\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"34\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"35\")]),a(\"br\")])]),a(\"p\",[t._v(\"然后将以下代码添加到您的\"),a(\"code\",[t._v(\"run\")]),t._v(\"函数中。\")]),t._v(\" \"),a(\"div\",{staticClass:\"language-js line-numbers-mode\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-js\"}},[a(\"code\",[a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" model \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getModel\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\ntfvis\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"show\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"modelSummary\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"name\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'Model Architecture'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" model\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \\n\"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"await\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"train\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"model\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" data\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\")])]),t._v(\" \"),a(\"div\",{staticClass:\"line-numbers-wrapper\"},[a(\"span\",{staticClass:\"line-number\"},[t._v(\"1\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"2\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"3\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"4\")]),a(\"br\")])]),a(\"p\",[t._v(\"刷新页面，几秒钟后，您应该会看到一些图形报告培训进度。\")]),t._v(\" \"),a(\"p\",[a(\"img\",{attrs:{src:\"https://codelabs.developers.google.com/codelabs/tfjs-training-classfication/img/a2c7628dc47d465.png\",alt:\"\"}})]),t._v(\" \"),a(\"p\",[t._v(\"让我们更详细地看一下。\")]),t._v(\" \"),a(\"h3\",{attrs:{id:\"监控指标\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#监控指标\"}},[t._v(\"#\")]),t._v(\" 监控指标\")]),t._v(\" \"),a(\"div\",{staticClass:\"language-js line-numbers-mode\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-js\"}},[a(\"code\",[a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" metrics \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'loss'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'val_loss'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'acc'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'val_acc'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\")])]),t._v(\" \"),a(\"div\",{staticClass:\"line-numbers-wrapper\"},[a(\"span\",{staticClass:\"line-number\"},[t._v(\"1\")]),a(\"br\")])]),a(\"p\",[t._v(\"在这里，我们决定要监视哪些指标。我们将监视训练集的损失和准确性以及验证集的损失和准确性（分别为val_loss和val_acc）。我们将在下面详细讨论验证集。\")]),t._v(\" \"),a(\"blockquote\",[a(\"p\",[t._v(\"切记：使用Layers API时，每批都会计算损失，而每个时期后都会对整个数据集计算准确性。\")])]),t._v(\" \"),a(\"h3\",{attrs:{id:\"准备数据作为张量\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#准备数据作为张量\"}},[t._v(\"#\")]),t._v(\" 准备数据作为张量\")]),t._v(\" \"),a(\"div\",{staticClass:\"language-js line-numbers-mode\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-js\"}},[a(\"code\",[a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"BATCH_SIZE\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"512\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"TRAIN_DATA_SIZE\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"5500\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"TEST_DATA_SIZE\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1000\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"trainXs\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" trainYs\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" tf\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"tidy\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=>\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" d \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" data\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"nextTrainBatch\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"TRAIN_DATA_SIZE\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"return\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"\\n    d\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"xs\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"reshape\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"TRAIN_DATA_SIZE\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"28\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"28\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n    d\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"labels\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"testXs\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" testYs\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" tf\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"tidy\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=>\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" d \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" data\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"nextTestBatch\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"TEST_DATA_SIZE\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"return\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"\\n    d\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"xs\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"reshape\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"TEST_DATA_SIZE\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"28\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"28\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n    d\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"labels\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\")])]),t._v(\" \"),a(\"div\",{staticClass:\"line-numbers-wrapper\"},[a(\"span\",{staticClass:\"line-number\"},[t._v(\"1\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"2\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"3\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"4\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"5\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"6\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"7\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"8\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"9\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"10\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"11\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"12\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"13\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"14\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"15\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"16\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"17\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"18\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"19\")]),a(\"br\")])]),a(\"p\",[t._v(\"在这里，我们创建了两个数据集，一个训练集，我们将在该训练集上训练模型，一个验证集，我们将在每个时期结束时对其进行测试，但是在训练过程中，验证集中的数据永远不会显示给模型。\")]),t._v(\" \"),a(\"p\",[t._v(\"我们提供的数据类使从图像数据中轻松获得张量变得容易。但是我们仍然可以将张量整形为模型期望的形状，例如\"),a(\"code\",[t._v(\"[num_examples，image_width，image_height，channels]\")]),t._v(\"，然后才能将它们输入模型。对于每个数据集，我们都有输入（Xs）和标签（Ys）。\")]),t._v(\" \"),a(\"blockquote\",[a(\"p\",[t._v(\"注意：trainDataSize设置为5500，testDataSize设置为1000，以使其更快地进行实验。一旦运行了本教程，就可以将其分别增加到55000和10000。训练将花费更长的时间，但仍然可以在许多机器的浏览器中使用。\")])]),t._v(\" \"),a(\"div\",{staticClass:\"language-js line-numbers-mode\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-js\"}},[a(\"code\",[a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"return\")]),t._v(\" model\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"fit\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"trainXs\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" trainYs\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n  batchSize\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"BATCH_SIZE\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n  validationData\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"testXs\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" testYs\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n  epochs\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"10\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n  shuffle\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[t._v(\"true\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"\\n  callbacks\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" fitCallbacks\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\")])]),t._v(\" \"),a(\"div\",{staticClass:\"line-numbers-wrapper\"},[a(\"span\",{staticClass:\"line-number\"},[t._v(\"1\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"2\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"3\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"4\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"5\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"6\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"7\")]),a(\"br\")])]),a(\"p\",[t._v(\"我们调用\"),a(\"code\",[t._v(\"model.fit\")]),t._v(\"开始训练循环。我们还传递了\"),a(\"code\",[t._v(\"validationData\")]),t._v(\"属性，以指示模型在每个时期之后应使用哪些数据来进行自我测试（但不用于训练）。\")]),t._v(\" \"),a(\"p\",[t._v(\"如果我们在训练数据上做得很好，但在验证数据上做得不好，则意味着该模型可能\"),a(\"a\",{attrs:{href:\"https://developers.google.com/machine-learning/glossary/#overfitting\",target:\"_blank\",rel:\"noopener noreferrer\"}},[t._v(\"过度适合\"),a(\"OutboundLink\")],1),t._v(\"了训练数据，并且无法很好地\"),a(\"a\",{attrs:{href:\"https://developers.google.com/machine-learning/glossary/#generalization\",target:\"_blank\",rel:\"noopener noreferrer\"}},[t._v(\"推广\"),a(\"OutboundLink\")],1),t._v(\"到以前从未见过的输入。\")]),t._v(\" \"),a(\"h2\",{attrs:{id:\"_7-评估我们的模型\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_7-评估我们的模型\"}},[t._v(\"#\")]),t._v(\" 7.评估我们的模型\")]),t._v(\" \"),a(\"p\",[t._v(\"验证准确性可以很好地估计我们的模型将如何处理之前从未见过的数据（只要该数据在某种程度上类似于验证集）。但是，我们可能需要更详细的分类信息。\")]),t._v(\" \"),a(\"p\",[t._v(\"tfjs-vis中有两种方法可以帮助您解决此问题。\")]),t._v(\" \"),a(\"p\",[a(\"strong\",[t._v(\"将以下代码添加到\"),a(\"code\",[t._v(\"script.js\")]),t._v(\"文件的底部\")])]),t._v(\" \"),a(\"div\",{staticClass:\"language-js line-numbers-mode\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-js\"}},[a(\"code\",[a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" classNames \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'Zero'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'One'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'Two'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'Three'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'Four'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'Five'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'Six'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'Seven'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'Eight'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'Nine'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"function\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"doPrediction\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token parameter\"}},[t._v(\"model\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" data\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" testDataSize \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"500\")])]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"IMAGE_WIDTH\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"28\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"IMAGE_HEIGHT\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"28\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" testData \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" data\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"nextTestBatch\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"testDataSize\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" testxs \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" testData\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"xs\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"reshape\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"testDataSize\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"IMAGE_WIDTH\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"IMAGE_HEIGHT\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" labels \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" testData\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"labels\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"argMax\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"-\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" preds \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" model\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"predict\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"testxs\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"argMax\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"-\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n  testxs\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"dispose\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"return\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"preds\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" labels\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\\n\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"async\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"function\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"showAccuracy\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token parameter\"}},[t._v(\"model\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" data\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"preds\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" labels\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"doPrediction\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"model\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" data\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" classAccuracy \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"await\")]),t._v(\" tfvis\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"metrics\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"perClassAccuracy\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"labels\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" preds\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" container \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"name\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'Accuracy'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" tab\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'Evaluation'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  tfvis\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"show\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"perClassAccuracy\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"container\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" classAccuracy\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" classNames\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n  labels\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"dispose\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"async\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"function\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"showConfusion\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token parameter\"}},[t._v(\"model\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" data\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"preds\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" labels\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"doPrediction\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"model\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" data\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" confusionMatrix \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"await\")]),t._v(\" tfvis\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"metrics\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"confusionMatrix\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"labels\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" preds\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" container \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"name\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'Confusion Matrix'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" tab\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'Evaluation'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  tfvis\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"render\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"confusionMatrix\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"\\n      container\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"values\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" confusionMatrix\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" classNames\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n  labels\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"dispose\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\")])]),t._v(\" \"),a(\"div\",{staticClass:\"line-numbers-wrapper\"},[a(\"span\",{staticClass:\"line-number\"},[t._v(\"1\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"2\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"3\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"4\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"5\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"6\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"7\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"8\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"9\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"10\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"11\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"12\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"13\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"14\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"15\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"16\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"17\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"18\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"19\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"20\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"21\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"22\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"23\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"24\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"25\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"26\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"27\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"28\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"29\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"30\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"31\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"32\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"33\")]),a(\"br\")])]),a(\"p\",[t._v(\"这段代码在做什么？\")]),t._v(\" \"),a(\"ul\",[a(\"li\",[t._v(\"做出预测。\")]),t._v(\" \"),a(\"li\",[t._v(\"计算准确性指标。\")]),t._v(\" \"),a(\"li\",[t._v(\"显示指标\")])]),t._v(\" \"),a(\"p\",[t._v(\"让我们仔细看看每个步骤。\")]),t._v(\" \"),a(\"h3\",{attrs:{id:\"作出预测\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#作出预测\"}},[t._v(\"#\")]),t._v(\" 作出预测\")]),t._v(\" \"),a(\"div\",{staticClass:\"language-js line-numbers-mode\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-js\"}},[a(\"code\",[a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"function\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"doPrediction\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token parameter\"}},[t._v(\"model\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" data\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" testDataSize \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"500\")])]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"IMAGE_WIDTH\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"28\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"IMAGE_HEIGHT\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"28\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" testData \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" data\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"nextTestBatch\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"testDataSize\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" testxs \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" testData\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"xs\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"reshape\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"testDataSize\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"IMAGE_WIDTH\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[t._v(\"IMAGE_HEIGHT\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" labels \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" testData\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"labels\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"argMax\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"-\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" preds \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" model\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"predict\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"testxs\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"argMax\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"-\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n  testxs\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"dispose\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"return\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"preds\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" labels\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"  \\n\")])]),t._v(\" \"),a(\"div\",{staticClass:\"line-numbers-wrapper\"},[a(\"span\",{staticClass:\"line-number\"},[t._v(\"1\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"2\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"3\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"4\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"5\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"6\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"7\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"8\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"9\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"10\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"11\")]),a(\"br\")])]),a(\"p\",[t._v(\"首先，我们需要做出一些预测。在这里，我们将拍摄500张图像并预测其中的位数（您可以稍后增加此数字以测试更大的图像集）。值得注意的是，\"),a(\"code\",[t._v(\"argmax\")]),t._v(\"函数为我们提供了最高概率类别的索引。请记住，模型为每个类别输出一个概率。在这里，我们找出最高的概率并将其用作预测。\")]),t._v(\" \"),a(\"p\",[t._v(\"您可能还会注意到，我们可以一次对所有500个示例进行预测。这就是\"),a(\"code\",[t._v(\"TensorFlow.js\")]),t._v(\"提供的矢量化功能。\")]),t._v(\" \"),a(\"blockquote\",[a(\"p\",[a(\"strong\",[t._v(\"Note\")]),t._v(\":注意：此处我们不使用任何概率阈值。即使是相对较低的值，我们也会取最高值。此项目的一个有趣扩展是设置一些所需的最小概率，如果没有班级达到此分类阈值，则指示“未找到数字”。\")])]),t._v(\" \"),a(\"blockquote\",[a(\"p\",[a(\"strong\",[t._v(\"doPredictions\")]),t._v(\":显示了模型训练后通常如何进行预测。但是，对于新数据，您将没有任何现有标签\")])]),t._v(\" \"),a(\"h3\",{attrs:{id:\"显示每一个指标的准确性\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#显示每一个指标的准确性\"}},[t._v(\"#\")]),t._v(\" 显示每一个指标的准确性\")]),t._v(\" \"),a(\"div\",{staticClass:\"language-js line-numbers-mode\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-js\"}},[a(\"code\",[a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"async\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"function\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"showAccuracy\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"preds\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" labels\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"doPrediction\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" classAccuracy \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"await\")]),t._v(\" tfvis\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"metrics\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"perClassAccuracy\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"labels\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" preds\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" container \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\" name\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'Accuracy'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" tab\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'Evaluation'\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  tfvis\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"show\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"perClassAccuracy\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"container\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" classAccuracy\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" classNames\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n  labels\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"dispose\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"  \\n\")])]),t._v(\" \"),a(\"div\",{staticClass:\"line-numbers-wrapper\"},[a(\"span\",{staticClass:\"line-number\"},[t._v(\"1\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"2\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"3\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"4\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"5\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"6\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"7\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"8\")]),a(\"br\")])]),a(\"p\",[t._v(\"使用一组预测和标签，我们可以计算每个类别的准确性。\")]),t._v(\" \"),a(\"h3\",{attrs:{id:\"显示混乱矩阵\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#显示混乱矩阵\"}},[t._v(\"#\")]),t._v(\" 显示混乱矩阵\")]),t._v(\" \"),a(\"div\",{staticClass:\"language-js line-numbers-mode\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-js\"}},[a(\"code\",[a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"async\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"function\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"showConfusion\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"preds\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" labels\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"doPrediction\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" confusionMatrix \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"await\")]),t._v(\" tfvis\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"metrics\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"confusionMatrix\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"labels\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" preds\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" container \"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\" name\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'Confusion Matrix'\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" tab\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"'Evaluation'\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n  tfvis\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),t._v(\"render\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"confusionMatrix\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"\\n      container\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"values\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\":\")]),t._v(\" confusionMatrix\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" classNames\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n  labels\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"dispose\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"  \\n\")])]),t._v(\" \"),a(\"div\",{staticClass:\"line-numbers-wrapper\"},[a(\"span\",{staticClass:\"line-number\"},[t._v(\"1\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"2\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"3\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"4\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"5\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"6\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"7\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"8\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"9\")]),a(\"br\")])]),a(\"p\",[t._v(\"混淆矩阵类似于每个指标的准确度，但会进一步细分以显示错误分类的模式。它使您可以查看模型是否对任何特定的指标对感到困惑。\")]),t._v(\" \"),a(\"h3\",{attrs:{id:\"显示评估\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#显示评估\"}},[t._v(\"#\")]),t._v(\" 显示评估\")]),t._v(\" \"),a(\"p\",[t._v(\"将以下代码添加到\"),a(\"code\",[t._v(\"run\")]),t._v(\"函数的底部以显示评估。\")]),t._v(\" \"),a(\"div\",{staticClass:\"language-js line-numbers-mode\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-js\"}},[a(\"code\",[a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"await\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"showAccuracy\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"model\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" data\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"await\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"showConfusion\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"model\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" data\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\")])]),t._v(\" \"),a(\"div\",{staticClass:\"line-numbers-wrapper\"},[a(\"span\",{staticClass:\"line-number\"},[t._v(\"1\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[t._v(\"2\")]),a(\"br\")])]),a(\"p\",[t._v(\"您应该看到如下所示的显示。\")]),t._v(\" \"),a(\"p\",[a(\"img\",{attrs:{src:\"https://codelabs.developers.google.com/codelabs/tfjs-training-classfication/img/82458197bd5e7f52.png\",alt:\"\"}})]),t._v(\" \"),a(\"h2\",{attrs:{id:\"_8-主要要点\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_8-主要要点\"}},[t._v(\"#\")]),t._v(\" 8.主要要点\")]),t._v(\" \"),a(\"p\",[t._v(\"预测输入数据的类别称为分类任务。\")]),t._v(\" \"),a(\"p\",[t._v(\"分类任务要求标签具有适当的数据表示形式\")]),t._v(\" \"),a(\"ul\",[a(\"li\",[t._v(\"标签的常见表示形式包括类别的一键编码\\n准备数据：\")]),t._v(\" \"),a(\"li\",[t._v(\"将一些在训练期间从未见过的数据放在一边，这对于您可以用来评估模型很有用。这称为验证集。\")])]),t._v(\" \"),a(\"p\",[t._v(\"构建并运行模型：\")]),t._v(\" \"),a(\"ul\",[a(\"li\",[t._v(\"卷积模型已显示在图像任务上表现良好。\")]),t._v(\" \"),a(\"li\",[t._v(\"分类问题通常使用分类交叉熵作为其损失函数。\")]),t._v(\" \"),a(\"li\",[t._v(\"监视训练以查看损失是否正在减少并且准确性正在增加。\")])]),t._v(\" \"),a(\"p\",[t._v(\"评估模型\")]),t._v(\" \"),a(\"ul\",[a(\"li\",[t._v(\"一旦训练了模型以决定要解决的初始问题的性能如何，就可以决定评估模型的方式。\")]),t._v(\" \"),a(\"li\",[t._v(\"每类准确性和混淆矩阵可以为您提供比整体准确性更好的模型性能细分。\")])])])}),[],!1,null,null,null);s.default=e.exports}}]);","extractedComments":[]}